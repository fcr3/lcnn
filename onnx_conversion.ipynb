{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import pprint\n",
    "import random\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import torch\n",
    "import yaml\n",
    "from docopt import docopt\n",
    "\n",
    "import lcnn\n",
    "from lcnn.config import C, M\n",
    "from lcnn.models.line_vectorizer import LineVectorizer\n",
    "from lcnn.models.multitask_learner import MultitaskHead, MultitaskLearner\n",
    "from lcnn.postprocess import postprocess\n",
    "from lcnn.utils import recursive_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'io': {   'datadir': 'data/wireframe/',\n",
      "              'logdir': 'logs/',\n",
      "              'num_workers': 4,\n",
      "              'resume_from': None,\n",
      "              'tensorboard_port': 0,\n",
      "              'validation_interval': 24000},\n",
      "    'model': {   'backbone': 'stacked_hourglass',\n",
      "                 'batch_size': 6,\n",
      "                 'batch_size_eval': 2,\n",
      "                 'depth': 4,\n",
      "                 'dim_fc': 1024,\n",
      "                 'dim_loi': 128,\n",
      "                 'eval_junc_thres': 0.008,\n",
      "                 'head_size': <BoxList: [[2], [1], [2]]>,\n",
      "                 'image': {   'mean': <BoxList: [109.73, 103.832, 98.681]>,\n",
      "                              'stddev': <BoxList: [22.275, 22.124, 23.229]>},\n",
      "                 'loss_weight': {   'jmap': 8.0,\n",
      "                                    'joff': 0.25,\n",
      "                                    'lmap': 0.5,\n",
      "                                    'lneg': 1,\n",
      "                                    'lpos': 1},\n",
      "                 'n_dyn_junc': 300,\n",
      "                 'n_dyn_negl': 80,\n",
      "                 'n_dyn_othr': 600,\n",
      "                 'n_dyn_posl': 300,\n",
      "                 'n_out_junc': 250,\n",
      "                 'n_out_line': 2500,\n",
      "                 'n_pts0': 32,\n",
      "                 'n_pts1': 8,\n",
      "                 'n_stc_negl': 40,\n",
      "                 'n_stc_posl': 300,\n",
      "                 'num_blocks': 1,\n",
      "                 'num_stacks': 2,\n",
      "                 'use_conv': 0,\n",
      "                 'use_cood': 0,\n",
      "                 'use_slop': 0},\n",
      "    'optim': {   'amsgrad': True,\n",
      "                 'lr': 0.0004,\n",
      "                 'lr_decay_epoch': 10,\n",
      "                 'max_epoch': 24,\n",
      "                 'name': 'Adam',\n",
      "                 'weight_decay': 0.0001}}\n",
      "Let's use 1 GPU(s)!\n"
     ]
    }
   ],
   "source": [
    "# args = docopt(__doc__)\n",
    "config_file = \"config/wireframe.yaml\"\n",
    "C.update(C.from_yaml(filename=config_file))\n",
    "M.update(C.model)\n",
    "pprint.pprint(C, indent=4)\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device_name = \"cpu\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = args[\"--devices\"]\n",
    "if torch.cuda.is_available():\n",
    "    device_name = \"cuda\"\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.cuda.manual_seed(0)\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPU(s)!\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")\n",
    "device = torch.device(device_name)\n",
    "checkpoint = torch.load(\"190418-201834-f8934c6-lr4d10-312k.pth.tar\", \n",
    "                        map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LineVectorizer(\n",
       "  (backbone): MultitaskLearner(\n",
       "    (backbone): HourglassNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck2D(\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck2D(\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck2D(\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (hg): ModuleList(\n",
       "        (0): Hourglass(\n",
       "          (hg): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (3): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ModuleList(\n",
       "              (0): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ModuleList(\n",
       "              (0): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): ModuleList(\n",
       "              (0): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Hourglass(\n",
       "          (hg): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (3): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ModuleList(\n",
       "              (0): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ModuleList(\n",
       "              (0): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): ModuleList(\n",
       "              (0): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Sequential(\n",
       "                (0): Bottleneck2D(\n",
       "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (relu): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (res): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Bottleneck2D(\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Bottleneck2D(\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fc): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (score): ModuleList(\n",
       "        (0): MultitaskHead(\n",
       "          (heads): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): Sequential(\n",
       "              (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): MultitaskHead(\n",
       "          (heads): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): Sequential(\n",
       "              (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fc_): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (score_): ModuleList(\n",
       "        (0): Conv2d(5, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (pooling): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=1032, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  )\n",
       "  (loss): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading model\n",
    "model = lcnn.models.hg(\n",
    "    depth=M.depth,\n",
    "    head=lambda c_in, c_out: MultitaskHead(c_in, c_out),\n",
    "    num_stacks=M.num_stacks,\n",
    "    num_blocks=M.num_blocks,\n",
    "    num_classes=sum(sum(M.head_size, [])),\n",
    ")\n",
    "model = MultitaskLearner(model)\n",
    "model = LineVectorizer(model)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 512, 512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grabbing random image\n",
    "im = skimage.io.imread(\"/home/fcr/Pictures/photo_stuff.JPG\")\n",
    "if im.ndim == 2:\n",
    "    im = np.repeat(im[:, :, None], 3, 2)\n",
    "im = im[:, :, :3]\n",
    "im_resized = skimage.transform.resize(im, (512, 512)) * 255\n",
    "image = (im_resized - M.image.mean) / M.image.stddev\n",
    "image = torch.from_numpy(np.rollaxis(image, 2)[None].copy()).float()\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f4114610e041>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"testing\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m }\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/OpenARK_env/lib/python3.6/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OpenARK_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/lcnn/lcnn/models/line_vectorizer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_dict)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"preds\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feature\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OpenARK_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/lcnn/lcnn/models/multitask_learner.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_dict)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"feature\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 4"
     ]
    }
   ],
   "source": [
    "input_dict = {\n",
    "    \"image\": image.to(device),\n",
    "    \"meta\": [\n",
    "        {\n",
    "            \"junc\": torch.zeros(1, 2).to(device),\n",
    "            \"jtyp\": torch.zeros(1, dtype=torch.uint8).to(device),\n",
    "            \"Lpos\": torch.zeros(2, 2, dtype=torch.uint8).to(device),\n",
    "            \"Lneg\": torch.zeros(2, 2, dtype=torch.uint8).to(device),\n",
    "        }\n",
    "    ],\n",
    "    \"target\": {\n",
    "        \"jmap\": torch.zeros([1, 1, 128, 128]).to(device),\n",
    "        \"joff\": torch.zeros([1, 1, 2, 128, 128]).to(device),\n",
    "    },\n",
    "    \"mode\": \"testing\",\n",
    "}\n",
    "summary(model, input_size=(3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    input_dict = {\n",
    "        \"image\": image.to(device),\n",
    "        \"meta\": [\n",
    "            {\n",
    "                \"junc\": torch.zeros(1, 2).to(device),\n",
    "                \"jtyp\": torch.zeros(1, dtype=torch.uint8).to(device),\n",
    "                \"Lpos\": torch.zeros(2, 2, dtype=torch.uint8).to(device),\n",
    "                \"Lneg\": torch.zeros(2, 2, dtype=torch.uint8).to(device),\n",
    "            }\n",
    "        ],\n",
    "        \"target\": {\n",
    "            \"jmap\": torch.zeros([1, 1, 128, 128]).to(device),\n",
    "            \"joff\": torch.zeros([1, 1, 2, 128, 128]).to(device),\n",
    "        },\n",
    "        \"mode\": \"testing\",\n",
    "    }\n",
    "    model_out = model(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': tensor([[[[0.7589, 0.8255, 0.4786,  ..., 0.5998, 1.0855, 1.0054],\n",
       "           [0.9022, 0.6508, 0.3571,  ..., 0.5829, 0.7833, 0.9299],\n",
       "           [0.7404, 0.5643, 0.3696,  ..., 0.4243, 0.5113, 0.7684],\n",
       "           ...,\n",
       "           [1.0381, 0.8115, 0.6234,  ..., 0.3036, 0.6313, 0.8480],\n",
       "           [1.0483, 0.7447, 0.6298,  ..., 0.7488, 0.6024, 0.7668],\n",
       "           [0.9986, 0.9757, 0.9153,  ..., 1.0050, 0.6442, 0.6412]],\n",
       " \n",
       "          [[0.0287, 0.1454, 0.0619,  ..., 0.1879, 0.2072, 0.0857],\n",
       "           [0.1558, 0.1764, 0.1529,  ..., 0.2814, 0.2966, 0.2091],\n",
       "           [0.1383, 0.2292, 0.1491,  ..., 0.2525, 0.2828, 0.1659],\n",
       "           ...,\n",
       "           [0.1509, 0.2563, 0.1932,  ..., 0.2135, 0.2475, 0.1456],\n",
       "           [0.1828, 0.2519, 0.2320,  ..., 0.2031, 0.2349, 0.1565],\n",
       "           [0.1055, 0.2078, 0.1860,  ..., 0.1635, 0.1724, 0.0916]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0069,  ..., 0.0053, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0039, 0.0073,  ..., 0.0092, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0270, 0.0476, 0.0593,  ..., 0.0422, 0.0218, 0.0000],\n",
       "           [0.0027, 0.0343, 0.0420,  ..., 0.0309, 0.0289, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0379, 0.0000, 0.0000,  ..., 0.1212, 0.4679, 0.6041],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3172],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0770, 0.3584, 0.5616],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0925, 0.2120, 0.5832],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.1768, 0.2882, 0.5930],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.3117, 0.3907, 0.3661]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0539,  ..., 0.0380, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.1129, 0.1785,  ..., 0.1593, 0.0533, 0.0000],\n",
       "           [0.0000, 0.0698, 0.1251,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0526,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.3572, 0.0000, 0.2198,  ..., 0.1499, 0.0000, 0.0944],\n",
       "           [0.0893, 0.1126, 0.2966,  ..., 0.1546, 0.0000, 0.0290],\n",
       "           [0.7837, 0.5498, 0.7305,  ..., 0.4882, 0.3251, 0.5198],\n",
       "           ...,\n",
       "           [0.7567, 0.6638, 0.6321,  ..., 0.3483, 0.1886, 0.2430],\n",
       "           [0.1845, 0.3039, 0.3223,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.2666, 0.0000, 0.2493,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
       "        device='cuda:0'),\n",
       " 'preds': {'jmap': tensor([[[[2.7470e-03, 9.7689e-04, 1.9998e-03,  ..., 3.3241e-04,\n",
       "             2.4612e-04, 1.5828e-03],\n",
       "            [6.8472e-04, 1.9059e-04, 3.5469e-04,  ..., 4.9952e-05,\n",
       "             3.4331e-05, 2.5572e-04],\n",
       "            [4.1844e-04, 8.9892e-05, 1.6388e-04,  ..., 5.9331e-05,\n",
       "             3.8179e-05, 2.5329e-04],\n",
       "            ...,\n",
       "            [1.5665e-04, 1.7765e-05, 2.4664e-05,  ..., 6.2337e-05,\n",
       "             2.7123e-05, 1.3782e-04],\n",
       "            [2.0596e-04, 2.6792e-05, 2.6702e-05,  ..., 5.3256e-05,\n",
       "             3.1379e-05, 1.6447e-04],\n",
       "            [1.4149e-03, 2.6251e-04, 2.3561e-04,  ..., 3.5669e-04,\n",
       "             3.4377e-04, 1.9687e-03]]]], device='cuda:0'),\n",
       "  'lmap': tensor([[[0.0052, 0.0023, 0.0043,  ..., 0.0009, 0.0007, 0.0034],\n",
       "           [0.0020, 0.0014, 0.0025,  ..., 0.0004, 0.0003, 0.0011],\n",
       "           [0.0017, 0.0008, 0.0015,  ..., 0.0005, 0.0003, 0.0009],\n",
       "           ...,\n",
       "           [0.0009, 0.0003, 0.0004,  ..., 0.0004, 0.0002, 0.0008],\n",
       "           [0.0009, 0.0003, 0.0003,  ..., 0.0004, 0.0003, 0.0009],\n",
       "           [0.0030, 0.0009, 0.0010,  ..., 0.0011, 0.0009, 0.0029]]],\n",
       "         device='cuda:0'),\n",
       "  'joff': tensor([[[[[-0.2545, -0.3138, -0.3006,  ..., -0.3455, -0.3619, -0.2962],\n",
       "             [-0.0089, -0.0952, -0.1069,  ..., -0.0143,  0.0143, -0.0323],\n",
       "             [-0.0662, -0.1278, -0.1223,  ..., -0.0077, -0.0280, -0.0284],\n",
       "             ...,\n",
       "             [ 0.0231,  0.0158, -0.0016,  ...,  0.0414,  0.0331, -0.0097],\n",
       "             [ 0.0211, -0.0053, -0.0254,  ...,  0.0011,  0.0308,  0.0149],\n",
       "             [ 0.2770,  0.3127,  0.3171,  ...,  0.3393,  0.3526,  0.2677]],\n",
       "  \n",
       "            [[-0.2457,  0.0236,  0.0205,  ..., -0.0421,  0.0471,  0.2864],\n",
       "             [-0.3274,  0.0143, -0.0275,  ..., -0.0577,  0.0775,  0.3520],\n",
       "             [-0.3619,  0.0167, -0.0052,  ..., -0.0580,  0.0878,  0.3603],\n",
       "             ...,\n",
       "             [-0.3654,  0.0069,  0.0123,  ...,  0.0085,  0.0089,  0.3871],\n",
       "             [-0.3559,  0.0110, -0.0377,  ...,  0.0388,  0.0072,  0.3839],\n",
       "             [-0.2790,  0.0013, -0.0366,  ...,  0.0204,  0.0325,  0.2953]]]]],\n",
       "         device='cuda:0'),\n",
       "  'lines': tensor([[[[122.7536,   6.7003],\n",
       "            [  5.3554,   6.6761]],\n",
       "  \n",
       "           [[ 23.7209,  98.6467],\n",
       "            [ 23.2886, 105.2864]],\n",
       "  \n",
       "           [[ 93.7488,  47.5330],\n",
       "            [111.3720,   6.6529]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 80.6281,  59.6617],\n",
       "            [ 83.1673,  22.3466]],\n",
       "  \n",
       "           [[100.5947,  20.6145],\n",
       "            [101.4076,  15.3955]],\n",
       "  \n",
       "           [[122.4847, 121.2573],\n",
       "            [ 98.4746, 120.8014]]]], device='cuda:0'),\n",
       "  'score': tensor([[0.9969, 0.9960, 0.9950,  ..., 0.8837, 0.8790, 0.8780]],\n",
       "         device='cuda:0'),\n",
       "  'juncs': tensor([[[122.7536,   6.7003],\n",
       "           [ 81.3885,  45.5932],\n",
       "           [  5.4612,  44.7372],\n",
       "           [ 23.7209,  98.6467],\n",
       "           [  5.3712, 121.2493],\n",
       "           [  5.3554,   6.6761],\n",
       "           [ 93.7488,  47.5330],\n",
       "           [ 80.3419,  79.7133],\n",
       "           [122.4847, 121.2573],\n",
       "           [ 89.2989,  46.5376],\n",
       "           [ 86.2633,  59.7355],\n",
       "           [ 83.7221,  79.7397],\n",
       "           [ 17.6692,  20.7638],\n",
       "           [ 80.6281,  59.6617],\n",
       "           [ 93.3459,  98.3792],\n",
       "           [ 89.5964,  44.7104],\n",
       "           [122.4778,  26.4793],\n",
       "           [ 17.5376,  18.7805],\n",
       "           [ 93.5019, 104.4556],\n",
       "           [ 78.4340,  98.3474],\n",
       "           [ 84.1938,  59.6291],\n",
       "           [ 99.3542,  59.2901],\n",
       "           [ 24.1856, 100.4490],\n",
       "           [ 94.5470, 121.2128],\n",
       "           [100.5947,  20.6145],\n",
       "           [ 90.2918,  59.7611],\n",
       "           [ 98.4746, 120.8014],\n",
       "           [ 23.5561, 103.7067],\n",
       "           [ 83.1673,  22.3466],\n",
       "           [111.3720,   6.6529],\n",
       "           [ 80.7001,  57.6160],\n",
       "           [ 86.7795,  45.4923],\n",
       "           [ 23.2886, 105.2864],\n",
       "           [ 15.5333,  13.4675],\n",
       "           [ 83.4659,  20.5188],\n",
       "           [ 81.6047,  98.4614],\n",
       "           [ 78.3956, 103.3527],\n",
       "           [103.5039,  23.2227],\n",
       "           [ 21.6013, 105.5177],\n",
       "           [101.4076,  15.3955],\n",
       "           [ 93.3006, 102.7702],\n",
       "           [103.3318,  59.4675],\n",
       "           [100.5764,  22.7082],\n",
       "           [ 88.3594,  22.4599],\n",
       "           [ 88.6664,  11.6771],\n",
       "           [122.5047,  15.7279],\n",
       "           [106.6285,   6.7556],\n",
       "           [ 85.8171,  57.7084],\n",
       "           [122.7536,   6.7003],\n",
       "           [ 81.3885,  45.5932],\n",
       "           [  5.4612,  44.7372],\n",
       "           [ 23.7209,  98.6467],\n",
       "           [  5.3712, 121.2493],\n",
       "           [  5.3554,   6.6761],\n",
       "           [ 93.7488,  47.5330],\n",
       "           [ 80.3419,  79.7133],\n",
       "           [122.4847, 121.2573],\n",
       "           [ 89.2989,  46.5376],\n",
       "           [ 86.2633,  59.7355],\n",
       "           [ 83.7221,  79.7397],\n",
       "           [ 17.6692,  20.7638],\n",
       "           [ 80.6281,  59.6617],\n",
       "           [ 93.3459,  98.3792],\n",
       "           [ 89.5964,  44.7104],\n",
       "           [122.4778,  26.4793],\n",
       "           [ 17.5376,  18.7805],\n",
       "           [ 93.5019, 104.4556],\n",
       "           [ 78.4340,  98.3474],\n",
       "           [ 84.1938,  59.6291],\n",
       "           [ 99.3542,  59.2901],\n",
       "           [ 24.1856, 100.4490],\n",
       "           [ 94.5470, 121.2128],\n",
       "           [100.5947,  20.6145],\n",
       "           [ 90.2918,  59.7611],\n",
       "           [ 98.4746, 120.8014],\n",
       "           [ 23.5561, 103.7067],\n",
       "           [ 83.1673,  22.3466],\n",
       "           [111.3720,   6.6529],\n",
       "           [ 80.7001,  57.6160],\n",
       "           [ 86.7795,  45.4923],\n",
       "           [ 23.2886, 105.2864],\n",
       "           [ 15.5333,  13.4675],\n",
       "           [ 83.4659,  20.5188],\n",
       "           [ 81.6047,  98.4614],\n",
       "           [ 78.3956, 103.3527],\n",
       "           [103.5039,  23.2227],\n",
       "           [ 21.6013, 105.5177],\n",
       "           [101.4076,  15.3955],\n",
       "           [ 93.3006, 102.7702],\n",
       "           [103.3318,  59.4675],\n",
       "           [100.5764,  22.7082],\n",
       "           [ 88.3594,  22.4599],\n",
       "           [ 88.6664,  11.6771],\n",
       "           [122.5047,  15.7279],\n",
       "           [106.6285,   6.7556],\n",
       "           [ 85.8171,  57.7084],\n",
       "           [122.7536,   6.7003],\n",
       "           [ 81.3885,  45.5932],\n",
       "           [  5.4612,  44.7372],\n",
       "           [ 23.7209,  98.6467],\n",
       "           [  5.3712, 121.2493],\n",
       "           [  5.3554,   6.6761],\n",
       "           [ 93.7488,  47.5330],\n",
       "           [ 80.3419,  79.7133],\n",
       "           [122.4847, 121.2573],\n",
       "           [ 89.2989,  46.5376],\n",
       "           [ 86.2633,  59.7355],\n",
       "           [ 83.7221,  79.7397],\n",
       "           [ 17.6692,  20.7638],\n",
       "           [ 80.6281,  59.6617],\n",
       "           [ 93.3459,  98.3792],\n",
       "           [ 89.5964,  44.7104],\n",
       "           [122.4778,  26.4793],\n",
       "           [ 17.5376,  18.7805],\n",
       "           [ 93.5019, 104.4556],\n",
       "           [ 78.4340,  98.3474],\n",
       "           [ 84.1938,  59.6291],\n",
       "           [ 99.3542,  59.2901],\n",
       "           [ 24.1856, 100.4490],\n",
       "           [ 94.5470, 121.2128],\n",
       "           [100.5947,  20.6145],\n",
       "           [ 90.2918,  59.7611],\n",
       "           [ 98.4746, 120.8014],\n",
       "           [ 23.5561, 103.7067],\n",
       "           [ 83.1673,  22.3466],\n",
       "           [111.3720,   6.6529],\n",
       "           [ 80.7001,  57.6160],\n",
       "           [ 86.7795,  45.4923],\n",
       "           [ 23.2886, 105.2864],\n",
       "           [ 15.5333,  13.4675],\n",
       "           [ 83.4659,  20.5188],\n",
       "           [ 81.6047,  98.4614],\n",
       "           [ 78.3956, 103.3527],\n",
       "           [103.5039,  23.2227],\n",
       "           [ 21.6013, 105.5177],\n",
       "           [101.4076,  15.3955],\n",
       "           [ 93.3006, 102.7702],\n",
       "           [103.3318,  59.4675],\n",
       "           [100.5764,  22.7082],\n",
       "           [ 88.3594,  22.4599],\n",
       "           [ 88.6664,  11.6771],\n",
       "           [122.5047,  15.7279],\n",
       "           [106.6285,   6.7556],\n",
       "           [ 85.8171,  57.7084],\n",
       "           [122.7536,   6.7003],\n",
       "           [ 81.3885,  45.5932],\n",
       "           [  5.4612,  44.7372],\n",
       "           [ 23.7209,  98.6467],\n",
       "           [  5.3712, 121.2493],\n",
       "           [  5.3554,   6.6761],\n",
       "           [ 93.7488,  47.5330],\n",
       "           [ 80.3419,  79.7133],\n",
       "           [122.4847, 121.2573],\n",
       "           [ 89.2989,  46.5376],\n",
       "           [ 86.2633,  59.7355],\n",
       "           [ 83.7221,  79.7397],\n",
       "           [ 17.6692,  20.7638],\n",
       "           [ 80.6281,  59.6617],\n",
       "           [ 93.3459,  98.3792],\n",
       "           [ 89.5964,  44.7104],\n",
       "           [122.4778,  26.4793],\n",
       "           [ 17.5376,  18.7805],\n",
       "           [ 93.5019, 104.4556],\n",
       "           [ 78.4340,  98.3474],\n",
       "           [ 84.1938,  59.6291],\n",
       "           [ 99.3542,  59.2901],\n",
       "           [ 24.1856, 100.4490],\n",
       "           [ 94.5470, 121.2128],\n",
       "           [100.5947,  20.6145],\n",
       "           [ 90.2918,  59.7611],\n",
       "           [ 98.4746, 120.8014],\n",
       "           [ 23.5561, 103.7067],\n",
       "           [ 83.1673,  22.3466],\n",
       "           [111.3720,   6.6529],\n",
       "           [ 80.7001,  57.6160],\n",
       "           [ 86.7795,  45.4923],\n",
       "           [ 23.2886, 105.2864],\n",
       "           [ 15.5333,  13.4675],\n",
       "           [ 83.4659,  20.5188],\n",
       "           [ 81.6047,  98.4614],\n",
       "           [ 78.3956, 103.3527],\n",
       "           [103.5039,  23.2227],\n",
       "           [ 21.6013, 105.5177],\n",
       "           [101.4076,  15.3955],\n",
       "           [ 93.3006, 102.7702],\n",
       "           [103.3318,  59.4675],\n",
       "           [100.5764,  22.7082],\n",
       "           [ 88.3594,  22.4599],\n",
       "           [ 88.6664,  11.6771],\n",
       "           [122.5047,  15.7279],\n",
       "           [106.6285,   6.7556],\n",
       "           [ 85.8171,  57.7084],\n",
       "           [122.7536,   6.7003],\n",
       "           [ 81.3885,  45.5932],\n",
       "           [  5.4612,  44.7372],\n",
       "           [ 23.7209,  98.6467],\n",
       "           [  5.3712, 121.2493],\n",
       "           [  5.3554,   6.6761],\n",
       "           [ 93.7488,  47.5330],\n",
       "           [ 80.3419,  79.7133],\n",
       "           [122.4847, 121.2573],\n",
       "           [ 89.2989,  46.5376],\n",
       "           [ 86.2633,  59.7355],\n",
       "           [ 83.7221,  79.7397],\n",
       "           [ 17.6692,  20.7638],\n",
       "           [ 80.6281,  59.6617],\n",
       "           [ 93.3459,  98.3792],\n",
       "           [ 89.5964,  44.7104],\n",
       "           [122.4778,  26.4793],\n",
       "           [ 17.5376,  18.7805],\n",
       "           [ 93.5019, 104.4556],\n",
       "           [ 78.4340,  98.3474],\n",
       "           [ 84.1938,  59.6291],\n",
       "           [ 99.3542,  59.2901],\n",
       "           [ 24.1856, 100.4490],\n",
       "           [ 94.5470, 121.2128],\n",
       "           [100.5947,  20.6145],\n",
       "           [ 90.2918,  59.7611],\n",
       "           [ 98.4746, 120.8014],\n",
       "           [ 23.5561, 103.7067],\n",
       "           [ 83.1673,  22.3466],\n",
       "           [111.3720,   6.6529],\n",
       "           [ 80.7001,  57.6160],\n",
       "           [ 86.7795,  45.4923],\n",
       "           [ 23.2886, 105.2864],\n",
       "           [ 15.5333,  13.4675],\n",
       "           [ 83.4659,  20.5188],\n",
       "           [ 81.6047,  98.4614],\n",
       "           [ 78.3956, 103.3527],\n",
       "           [103.5039,  23.2227],\n",
       "           [ 21.6013, 105.5177],\n",
       "           [101.4076,  15.3955],\n",
       "           [ 93.3006, 102.7702],\n",
       "           [103.3318,  59.4675],\n",
       "           [100.5764,  22.7082],\n",
       "           [ 88.3594,  22.4599],\n",
       "           [ 88.6664,  11.6771],\n",
       "           [122.5047,  15.7279],\n",
       "           [106.6285,   6.7556],\n",
       "           [ 85.8171,  57.7084],\n",
       "           [122.7536,   6.7003],\n",
       "           [ 81.3885,  45.5932],\n",
       "           [  5.4612,  44.7372],\n",
       "           [ 23.7209,  98.6467],\n",
       "           [  5.3712, 121.2493],\n",
       "           [  5.3554,   6.6761],\n",
       "           [ 93.7488,  47.5330],\n",
       "           [ 80.3419,  79.7133],\n",
       "           [122.4847, 121.2573],\n",
       "           [ 89.2989,  46.5376]]], device='cuda:0')}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fcr/research/lcnn/lcnn/models/line_vectorizer.py:163: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  N = len(junc)\n",
      "/home/fcr/research/lcnn/lcnn/models/line_vectorizer.py:165: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  K = min(int((jmap > M.eval_junc_thres).float().sum().item()), max_K)\n",
      "/home/fcr/research/lcnn/lcnn/models/line_vectorizer.py:165: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  K = min(int((jmap > M.eval_junc_thres).float().sum().item()), max_K)\n",
      "/home/fcr/research/lcnn/lcnn/models/line_vectorizer.py:188: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  for t in range(n_type):\n",
      "/home/fcr/research/lcnn/lcnn/models/line_vectorizer.py:189: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator index_put_. This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.\n",
      "  match[t, jtyp[match[t]] != t] = N\n",
      "/home/fcr/research/lcnn/lcnn/models/line_vectorizer.py:244: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  jcs = [xy[i, score[i] > 0.03] for i in range(n_type)]\n",
      "/home/fcr/research/lcnn/lcnn/models/line_vectorizer.py:104: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  for i in range(n_batch):\n",
      "/home/fcr/research/lcnn/lcnn/models/line_vectorizer.py:105: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  p0 = p[idx[i] : idx[i + 1]]\n",
      "/home/fcr/research/lcnn/lcnn/models/line_vectorizer.py:106: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  s0 = s[idx[i] : idx[i + 1]]\n",
      "/home/fcr/research/lcnn/lcnn/models/line_vectorizer.py:107: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  mask = b[idx[i] : idx[i + 1]]\n",
      "/home/fcr/research/lcnn/lcnn/models/line_vectorizer.py:110: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if len(p0) == 0:\n",
      "/home/fcr/research/lcnn/lcnn/models/line_vectorizer.py:116: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  lines.append(p0[None, torch.arange(M.n_out_line) % len(p0)])\n",
      "/home/fcr/research/lcnn/lcnn/models/line_vectorizer.py:117: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  score.append(s0[None, torch.arange(M.n_out_line) % len(s0)])\n",
      "/home/fcr/research/lcnn/lcnn/models/line_vectorizer.py:119: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if len(jcs[i][j]) == 0:\n",
      "/home/fcr/research/lcnn/lcnn/models/line_vectorizer.py:122: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  None, torch.arange(M.n_out_junc) % len(jcs[i][j])\n",
      "/home/fcr/research/lcnn/lcnn/models/line_vectorizer.py:126: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  result[\"preds\"][\"juncs\"] = torch.cat([jcs[i][0] for i in range(n_batch)])\n",
      "/home/fcr/anaconda3/envs/OpenARK_env/lib/python3.6/site-packages/torch/onnx/symbolic_helper.py:246: UserWarning: You are trying to export the model with onnx:Resize for ONNX opset version 10. This operator might cause results to not match the expected results by PyTorch.\n",
      "ONNX's Upsample/Resize operator did not match Pytorch's Interpolation until opset 11. Attributes to determine how to transform the input were added in onnx:Resize in opset 11 to support Pytorch's behavior (like coordinate_transformation_mode and nearest_mode).\n",
      "We recommend using opset 11 and above for models using this operator. \n",
      "  \"\" + str(_export_onnx_opset_version) + \". \"\n",
      "/home/fcr/anaconda3/envs/OpenARK_env/lib/python3.6/site-packages/torch/onnx/symbolic_opset9.py:1951: UserWarning: Exporting aten::index operator of advanced indexing in opset 10 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
      "  \"If indices include negative values, the exported graph will produce incorrect results.\")\n",
      "/home/fcr/anaconda3/envs/OpenARK_env/lib/python3.6/site-packages/torch/onnx/utils.py:655: UserWarning: ONNX export failed on ATen operator argsort because torch.onnx.symbolic_opset10.argsort does not exist\n",
      "  .format(op_name, opset_version, op_name))\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'argsort'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9211bcf5c7cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                   \u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# whether to execute constant folding for optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                   \u001b[0minput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# the model's input names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                   \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'jmap'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'joff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# the model's output names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/OpenARK_env/lib/python3.6/site-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                         \u001b[0moperator_export_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopset_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_retain_param_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                         \u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                         strip_doc_string, dynamic_axes, keep_initializers_as_inputs)\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OpenARK_env/lib/python3.6/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0m_retain_param_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_retain_param_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mexample_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexample_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_doc_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrip_doc_string\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             dynamic_axes=dynamic_axes, keep_initializers_as_inputs=keep_initializers_as_inputs)\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OpenARK_env/lib/python3.6/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, propagate, opset_version, _retain_param_name, do_constant_folding, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size)\u001b[0m\n\u001b[1;32m    414\u001b[0m                                                         \u001b[0mexample_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpropagate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                                                         \u001b[0m_retain_param_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                                                         fixed_batch_size=fixed_batch_size)\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;31m# TODO: Don't allocate a in-memory string for the protobuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OpenARK_env/lib/python3.6/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, training, input_names, output_names, operator_export_type, example_outputs, propagate, _retain_param_name, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size)\u001b[0m\n\u001b[1;32m    294\u001b[0m     graph = _optimize_graph(graph, operator_export_type,\n\u001b[1;32m    295\u001b[0m                             \u001b[0m_disable_torch_constant_prop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_disable_torch_constant_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                             fixed_batch_size=fixed_batch_size, params_dict=params_dict)\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScriptModule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScriptFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OpenARK_env/lib/python3.6/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_optimize_graph\u001b[0;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_erase_number_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator_export_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_lint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OpenARK_env/lib/python3.6/site-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36m_run_symbolic_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_run_symbolic_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_symbolic_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OpenARK_env/lib/python3.6/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_run_symbolic_function\u001b[0;34m(g, n, inputs, env, operator_export_type)\u001b[0m\n\u001b[1;32m    654\u001b[0m                                   \u001b[0;34m\"torch.onnx.symbolic_opset{}.{} does not exist\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m                                   .format(op_name, opset_version, op_name))\n\u001b[0;32m--> 656\u001b[0;31m                 \u001b[0mop_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msym_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_registered_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopset_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OpenARK_env/lib/python3.6/site-packages/torch/onnx/symbolic_registry.py\u001b[0m in \u001b[0;36mget_registered_op\u001b[0;34m(opname, domain, version)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ONNX export failed. The ONNX domain and/or version are None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_registry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_registry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'argsort'"
     ]
    }
   ],
   "source": [
    "# Export the model\n",
    "torch.onnx.export(model,                     # model being run\n",
    "                  input_dict,                # model input (or a tuple for multiple inputs)\n",
    "                  \"lcnn.onnx\",               # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['image'],   # the model's input names\n",
    "                  output_names = ['jmap', 'joff'], # the model's output names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
